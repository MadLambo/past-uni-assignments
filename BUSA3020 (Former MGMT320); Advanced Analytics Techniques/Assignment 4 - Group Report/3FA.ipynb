{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3EFA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creditability</th>\n",
       "      <th>EFA1</th>\n",
       "      <th>EFA2</th>\n",
       "      <th>EFA3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.749079</td>\n",
       "      <td>1.585234</td>\n",
       "      <td>-0.033066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.628857</td>\n",
       "      <td>-0.761100</td>\n",
       "      <td>0.442160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.610113</td>\n",
       "      <td>1.410389</td>\n",
       "      <td>-0.394405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.330378</td>\n",
       "      <td>-1.640749</td>\n",
       "      <td>-0.264435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.971218</td>\n",
       "      <td>-1.967155</td>\n",
       "      <td>-0.751655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Creditability      EFA1      EFA2      EFA3\n",
       "0              1 -0.749079  1.585234 -0.033066\n",
       "1              1 -0.628857 -0.761100  0.442160\n",
       "2              1 -1.610113  1.410389 -0.394405\n",
       "3              1 -2.330378 -1.640749 -0.264435\n",
       "4              1 -1.971218 -1.967155 -0.751655"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EFA_three = pd.read_csv(\"Cluster_Predictive_0_-_3EFA.csv\")\n",
    "EFA_three.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 4)\n",
      "(300, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda 3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(EFA_three, test_size=0.3, random_state=0)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "y = EFA_three['Creditability']\n",
    "x = EFA_three.drop(['Creditability'], axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.6966666666666667\n",
      "Confusion Matrix = \n",
      " [[ 22  78]\n",
      " [ 13 187]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lg = logreg.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy score =\", accuracy_score(y_test, y_pred_lg))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "print(\"Confusion Matrix = \\n\", confusion_matrix(y_test, y_pred_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.629     0.220     0.326       100\n",
      "           1      0.706     0.935     0.804       200\n",
      "\n",
      "    accuracy                          0.697       300\n",
      "   macro avg      0.667     0.578     0.565       300\n",
      "weighted avg      0.680     0.697     0.645       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_lg, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.475     0.380     0.422       100\n",
      "           1      0.718     0.790     0.752       200\n",
      "\n",
      "    accuracy                          0.653       300\n",
      "   macro avg      0.597     0.585     0.587       300\n",
      "weighted avg      0.637     0.653     0.642       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda 3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier(random_state=0)\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred_rf = randomforest.predict(x_test)\n",
    "acc_randomforest = round(accuracy_score(y_pred_rf, y_test) * 100, 2)\n",
    "print(metrics.classification_report(y_test, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.645     0.200     0.305       100\n",
      "           1      0.703     0.945     0.806       200\n",
      "\n",
      "    accuracy                          0.697       300\n",
      "   macro avg      0.674     0.573     0.556       300\n",
      "weighted avg      0.683     0.697     0.639       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred_nb = gaussian.predict(x_test)\n",
    "acc_gaussian = round(accuracy_score(y_pred_nb, y_test) * 100, 2)\n",
    "print(metrics.classification_report(y_test, y_pred_nb, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Accuracy: 1.0\n",
      "Decision Tree Test Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.505     0.510     0.507       100\n",
      "           1      0.754     0.750     0.752       200\n",
      "\n",
      "    accuracy                          0.670       300\n",
      "   macro avg      0.629     0.630     0.630       300\n",
      "weighted avg      0.671     0.670     0.670       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "credit_tree = DecisionTreeClassifier(random_state=0)\n",
    "credit_tree .fit(x_train, y_train)\n",
    "\n",
    "y_train_predict_dt = credit_tree.predict(x_train)\n",
    "y_test_predict_dt = credit_tree.predict(x_test)\n",
    "\n",
    "print(\"Decision Tree Train Accuracy:\", accuracy_score(y_train_predict_dt, y_train))\n",
    "print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test_predict_dt, y_test))\n",
    "print(metrics.classification_report(y_test, y_test_predict_dt, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.579     0.330     0.420       100\n",
      "           1      0.724     0.880     0.795       200\n",
      "\n",
      "    accuracy                          0.697       300\n",
      "   macro avg      0.652     0.605     0.607       300\n",
      "weighted avg      0.676     0.697     0.670       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_knn = knn.predict(x_test)\n",
    "acc_knn = round(accuracy_score(y_pred_knn, y_test) * 100, 2)\n",
    "print(acc_knn)\n",
    "print(metrics.classification_report(y_test, y_pred_knn, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
