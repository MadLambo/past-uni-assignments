{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creditability</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.642221</td>\n",
       "      <td>1.493029</td>\n",
       "      <td>-0.783659</td>\n",
       "      <td>0.191257</td>\n",
       "      <td>0.755509</td>\n",
       "      <td>1.335644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.666487</td>\n",
       "      <td>-0.865975</td>\n",
       "      <td>-0.722274</td>\n",
       "      <td>1.478355</td>\n",
       "      <td>-0.972569</td>\n",
       "      <td>0.658638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.633176</td>\n",
       "      <td>1.335201</td>\n",
       "      <td>0.174067</td>\n",
       "      <td>-0.634806</td>\n",
       "      <td>-0.333530</td>\n",
       "      <td>0.241433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.442450</td>\n",
       "      <td>-1.893177</td>\n",
       "      <td>-1.056122</td>\n",
       "      <td>1.172955</td>\n",
       "      <td>-2.183220</td>\n",
       "      <td>0.398126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.313228</td>\n",
       "      <td>-1.844096</td>\n",
       "      <td>-1.077671</td>\n",
       "      <td>1.134547</td>\n",
       "      <td>-1.608855</td>\n",
       "      <td>-1.920328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Creditability       PC1       PC2       PC3       PC4       PC5       PC6\n",
       "0              1 -0.642221  1.493029 -0.783659  0.191257  0.755509  1.335644\n",
       "1              1 -0.666487 -0.865975 -0.722274  1.478355 -0.972569  0.658638\n",
       "2              1 -1.633176  1.335201  0.174067 -0.634806 -0.333530  0.241433\n",
       "3              1 -2.442450 -1.893177 -1.056122  1.172955 -2.183220  0.398126\n",
       "4              1 -2.313228 -1.844096 -1.077671  1.134547 -1.608855 -1.920328"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"PCA.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 7)\n",
      "(300, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda 3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=0)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "y = df['Creditability']\n",
    "x = df.drop(['Creditability'], axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.8966666666666666\n",
      "Confusion Matrix = \n",
      " [[ 80  20]\n",
      " [ 11 189]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lg = logreg.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy score =\", accuracy_score(y_test, y_pred_lg))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "print(\"Confusion Matrix = \\n\", confusion_matrix(y_test, y_pred_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.879     0.800     0.838       100\n",
      "           1      0.904     0.945     0.924       200\n",
      "\n",
      "    accuracy                          0.897       300\n",
      "   macro avg      0.892     0.873     0.881       300\n",
      "weighted avg      0.896     0.897     0.895       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_lg, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.879     0.800     0.838       100\n",
      "           1      0.904     0.945     0.924       200\n",
      "\n",
      "    accuracy                          0.897       300\n",
      "   macro avg      0.892     0.873     0.881       300\n",
      "weighted avg      0.896     0.897     0.895       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda 3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier(random_state=0)\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred_rf = randomforest.predict(x_test)\n",
    "acc_randomforest = round(accuracy_score(y_pred_rf, y_test) * 100, 2)\n",
    "print(metrics.classification_report(y_test, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.899     0.800     0.847       100\n",
      "           1      0.905     0.955     0.929       200\n",
      "\n",
      "    accuracy                          0.903       300\n",
      "   macro avg      0.902     0.877     0.888       300\n",
      "weighted avg      0.903     0.903     0.902       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred_nb = gaussian.predict(x_test)\n",
    "acc_gaussian = round(accuracy_score(y_pred_nb, y_test) * 100, 2)\n",
    "print(metrics.classification_report(y_test, y_pred_nb, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Accuracy: 1.0\n",
      "Decision Tree Test Accuracy: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.830     0.730     0.777       100\n",
      "           1      0.873     0.925     0.898       200\n",
      "\n",
      "    accuracy                          0.860       300\n",
      "   macro avg      0.851     0.828     0.837       300\n",
      "weighted avg      0.858     0.860     0.858       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "credit_tree = DecisionTreeClassifier(random_state=0)\n",
    "credit_tree .fit(x_train, y_train)\n",
    "\n",
    "y_train_predict_dt = credit_tree.predict(x_train)\n",
    "y_test_predict_dt = credit_tree.predict(x_test)\n",
    "\n",
    "print(\"Decision Tree Train Accuracy:\", accuracy_score(y_train_predict_dt, y_train))\n",
    "print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test_predict_dt, y_test))\n",
    "print(metrics.classification_report(y_test, y_test_predict_dt, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.922     0.710     0.802       100\n",
      "           1      0.870     0.970     0.917       200\n",
      "\n",
      "    accuracy                          0.883       300\n",
      "   macro avg      0.896     0.840     0.860       300\n",
      "weighted avg      0.887     0.883     0.879       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_knn = knn.predict(x_test)\n",
    "acc_knn = round(accuracy_score(y_pred_knn, y_test) * 100, 2)\n",
    "print(acc_knn)\n",
    "print(metrics.classification_report(y_test, y_pred_knn, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
