{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3F&3FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creditability</th>\n",
       "      <th>EFA1</th>\n",
       "      <th>EFA2</th>\n",
       "      <th>EFA3</th>\n",
       "      <th>TSC_3EFA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.749079</td>\n",
       "      <td>1.585234</td>\n",
       "      <td>-0.033066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.628857</td>\n",
       "      <td>-0.761100</td>\n",
       "      <td>0.442160</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.610113</td>\n",
       "      <td>1.410389</td>\n",
       "      <td>-0.394405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.330378</td>\n",
       "      <td>-1.640749</td>\n",
       "      <td>-0.264435</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.971218</td>\n",
       "      <td>-1.967155</td>\n",
       "      <td>-0.751655</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Creditability      EFA1      EFA2      EFA3  TSC_3EFA\n",
       "0              1 -0.749079  1.585234 -0.033066         1\n",
       "1              1 -0.628857 -0.761100  0.442160         3\n",
       "2              1 -1.610113  1.410389 -0.394405         1\n",
       "3              1 -2.330378 -1.640749 -0.264435         3\n",
       "4              1 -1.971218 -1.967155 -0.751655         3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4 = pd.read_csv(\"Cluster_Predictive_4_-_3F&3FC.csv\")\n",
    "pred4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 5)\n",
      "(300, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda 3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(pred4, test_size=0.3, random_state=0)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "y = pred4['Creditability']\n",
    "x = pred4.drop(['Creditability'], axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score = 0.7066666666666667\n",
      "Confusion Matrix = \n",
      " [[ 25  75]\n",
      " [ 13 187]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lg = logreg.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy score =\", accuracy_score(y_test, y_pred_lg))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "print(\"Confusion Matrix = \\n\", confusion_matrix(y_test, y_pred_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.658     0.250     0.362       100\n",
      "           1      0.714     0.935     0.810       200\n",
      "\n",
      "    accuracy                          0.707       300\n",
      "   macro avg      0.686     0.593     0.586       300\n",
      "weighted avg      0.695     0.707     0.660       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_lg, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.506     0.440     0.471       100\n",
      "           1      0.737     0.785     0.760       200\n",
      "\n",
      "    accuracy                          0.670       300\n",
      "   macro avg      0.621     0.613     0.615       300\n",
      "weighted avg      0.660     0.670     0.664       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda 3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier(random_state=0)\n",
    "randomforest.fit(x_train, y_train)\n",
    "y_pred_rf = randomforest.predict(x_test)\n",
    "acc_randomforest = round(accuracy_score(y_pred_rf, y_test) * 100, 2)\n",
    "print(metrics.classification_report(y_test, y_pred_rf, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.600     0.330     0.426       100\n",
      "           1      0.727     0.890     0.800       200\n",
      "\n",
      "    accuracy                          0.703       300\n",
      "   macro avg      0.663     0.610     0.613       300\n",
      "weighted avg      0.684     0.703     0.675       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "y_pred_nb = gaussian.predict(x_test)\n",
    "acc_gaussian = round(accuracy_score(y_pred_nb, y_test) * 100, 2)\n",
    "print(metrics.classification_report(y_test, y_pred_nb, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Accuracy: 1.0\n",
      "Decision Tree Test Accuracy: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.505     0.490     0.497       100\n",
      "           1      0.749     0.760     0.754       200\n",
      "\n",
      "    accuracy                          0.670       300\n",
      "   macro avg      0.627     0.625     0.626       300\n",
      "weighted avg      0.668     0.670     0.669       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "credit_tree = DecisionTreeClassifier(random_state=0)\n",
    "credit_tree .fit(x_train, y_train)\n",
    "\n",
    "y_train_predict_dt = credit_tree.predict(x_train)\n",
    "y_test_predict_dt = credit_tree.predict(x_test)\n",
    "\n",
    "print(\"Decision Tree Train Accuracy:\", accuracy_score(y_train_predict_dt, y_train))\n",
    "print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test_predict_dt, y_test))\n",
    "print(metrics.classification_report(y_test, y_test_predict_dt, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.561     0.320     0.408       100\n",
      "           1      0.720     0.875     0.790       200\n",
      "\n",
      "    accuracy                          0.690       300\n",
      "   macro avg      0.641     0.598     0.599       300\n",
      "weighted avg      0.667     0.690     0.663       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred_knn = knn.predict(x_test)\n",
    "acc_knn = round(accuracy_score(y_pred_knn, y_test) * 100, 2)\n",
    "print(acc_knn)\n",
    "print(metrics.classification_report(y_test, y_pred_knn, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
